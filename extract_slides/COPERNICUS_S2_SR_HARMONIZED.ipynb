{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fbb1482-be59-4f23-8629-2697f3ed50ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export tasks have been started.\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "# Initialize the Earth Engine module.\n",
    "# ee.Authenticate()\n",
    "ee.Initialize()\n",
    "\n",
    "# URL of the CSV file\n",
    "url = 'https://raw.githubusercontent.com/orwell2024/uscrnlib/main/extract_slides/2024stations_days.csv'\n",
    "\n",
    "# Read the CSV file from the URL\n",
    "response = requests.get(url)\n",
    "data = pd.read_csv(StringIO(response.text))\n",
    "\n",
    "# Limiting to first 10 locations for testing purposes\n",
    "data = data.head(4)\n",
    "\n",
    "# Function to create and export image for a given location\n",
    "def create_and_export_image(row):\n",
    "    station_name = row['Station']\n",
    "    latitude = row['LATITUDE']\n",
    "    longitude = row['LONGITUDE']\n",
    "    \n",
    "    point = ee.Geometry.Point([longitude, latitude])\n",
    "    buffer = point.buffer(10000).bounds()  # 5000 meters buffer for 10 km x 10 km region\n",
    "    \n",
    "    collection = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
    "                    .filterBounds(buffer) \\\n",
    "                    .filterDate('2023-04-11', '2023-6-01') \\\n",
    "                    .sort('CLOUDY_PIXEL_PERCENTAGE') \\\n",
    "                    .first()\n",
    "    \n",
    "    # Get the date of the image\n",
    "    date = ee.Date(collection.get('system:time_start')).format('YYYY-MM-dd').getInfo()\n",
    "    \n",
    "    # Select the relevant bands\n",
    "    image = collection.select(['B4', 'B3', 'B2']).clip(buffer)\n",
    "    \n",
    "    # Export the image with smaller dimensions\n",
    "    export_task = ee.batch.Export.image.toDrive(\n",
    "        image=image,\n",
    "        description=f\"{station_name}_{date}\",\n",
    "        folder='GEE_Images',\n",
    "        scale=10,\n",
    "        region=buffer.getInfo()['coordinates'],\n",
    "        fileFormat='GeoTIFF',  # Export as GeoTIFF\n",
    "        maxPixels=1e8\n",
    "    )\n",
    "    \n",
    "    export_task.start()\n",
    "\n",
    "# Apply the function to each row in the dataframe\n",
    "data.apply(create_and_export_image, axis=1)\n",
    "\n",
    "print(\"Export tasks have been started.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cec0d18-c0cc-4a30-8290-7dddfab72a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export tasks have been started and results have been written to the CSV file.\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "# Initialize the Earth Engine module.\n",
    "# ee.Authenticate()\n",
    "ee.Initialize()\n",
    "\n",
    "# URL of the CSV file\n",
    "url = 'https://raw.githubusercontent.com/orwell2024/uscrnlib/main/extract_slides/2024stations_days.csv'\n",
    "\n",
    "# Read the CSV file from the URL\n",
    "response = requests.get(url)\n",
    "data = pd.read_csv(StringIO(response.text))\n",
    "\n",
    "# Filter the data to include only stations from Alabama (AL)\n",
    "data_al = data[data['Station'].str.startswith('TX_')].copy()\n",
    "\n",
    "# Initialize lists to store results\n",
    "built_1975_percent_list = []\n",
    "built_2020_percent_list = []\n",
    "percentage_change_list = []\n",
    "\n",
    "# Function to create and export image for a given location\n",
    "def process_location(row):\n",
    "    station_name = row['Station']\n",
    "    latitude = row['LATITUDE']\n",
    "    longitude = row['LONGITUDE']\n",
    "    sizeKm = 10  # Size of the cell in kilometers\n",
    "\n",
    "    # Define a point for the center of the rectangle at the specified coordinates\n",
    "    centerPoint = ee.Geometry.Point([longitude, latitude])\n",
    "\n",
    "    # Create a bounding box around the center point\n",
    "    halfSideLength = (sizeKm / 2) * 1000  # Convert km to meters\n",
    "    cell = centerPoint.buffer(halfSideLength).bounds()\n",
    "\n",
    "    # Load the built-up surface images for 1975 and 2020 from the JRC GHSL dataset\n",
    "    image_1975 = ee.Image('JRC/GHSL/P2023A/GHS_BUILT_S/1975').select('built_surface')\n",
    "    image_2020 = ee.Image('JRC/GHSL/P2023A/GHS_BUILT_S/2020').select('built_surface')\n",
    "\n",
    "    # Clip the built-up images to the cell\n",
    "    built_1975_clipped = image_1975.clip(cell)\n",
    "    built_2020_clipped = image_2020.clip(cell)\n",
    "\n",
    "    # Calculate the average built-up value for the cell in 1975\n",
    "    mean1975 = built_1975_clipped.reduceRegion(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        geometry=cell,\n",
    "        scale=30,\n",
    "        maxPixels=1e9\n",
    "    ).get('built_surface').getInfo()\n",
    "\n",
    "    # Calculate the average built-up value for the cell in 2020\n",
    "    mean2020 = built_2020_clipped.reduceRegion(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        geometry=cell,\n",
    "        scale=30,\n",
    "        maxPixels=1e9\n",
    "    ).get('built_surface').getInfo()\n",
    "\n",
    "    # Normalize to percentage of the area (1% = 10,000 square meters per hectare)\n",
    "    percentage1975 = round((mean1975 / 10000) * 100, 2) if mean1975 is not None else 0\n",
    "    percentage2020 = round((mean2020 / 10000) * 100, 2) if mean2020 is not None else 0\n",
    "\n",
    "    # Calculate the percentage change\n",
    "    percentage_change = round(((percentage2020 - percentage1975) / percentage1975) * 100, 2) if percentage1975 != 0 else None\n",
    "\n",
    "    # Append results to lists\n",
    "    built_1975_percent_list.append(percentage1975)\n",
    "    built_2020_percent_list.append(percentage2020)\n",
    "    percentage_change_list.append(percentage_change)\n",
    "\n",
    "    # Export the 1975 image to Google Drive\n",
    "    export_task_1975 = ee.batch.Export.image.toDrive(\n",
    "        image=built_1975_clipped,\n",
    "        description=f'Built_up_surface_1975_{station_name}_{sizeKm}km_cell',\n",
    "        folder='GEE_Images',\n",
    "        scale=30,\n",
    "        region=cell,\n",
    "        maxPixels=1e9\n",
    "    )\n",
    "    export_task_1975.start()\n",
    "\n",
    "    # Export the 2020 image to Google Drive\n",
    "    export_task_2020 = ee.batch.Export.image.toDrive(\n",
    "        image=built_2020_clipped,\n",
    "        description=f'Built_up_surface_2020_{station_name}_{sizeKm}km_cell',\n",
    "        folder='GEE_Images',\n",
    "        scale=30,\n",
    "        region=cell,\n",
    "        maxPixels=1e9\n",
    "    )\n",
    "    export_task_2020.start()\n",
    "\n",
    "# Apply the function to each row in the filtered dataframe\n",
    "data_al.apply(process_location, axis=1)\n",
    "\n",
    "# Add the results to the dataframe\n",
    "data_al.loc[:, 'Built_1975_percent'] = built_1975_percent_list\n",
    "data_al.loc[:, 'Built_2020_percent'] = built_2020_percent_list\n",
    "data_al.loc[:, 'Percentage_Change'] = percentage_change_list\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "output_csv_path = 'updated_stations_data_al.csv'\n",
    "data_al.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(\"Export tasks have been started and results have been written to the CSV file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "060d364e-e2e1-432e-94fc-10f086da9c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing is complete and results have been written to the CSV file.\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "# Initialize the Earth Engine module.\n",
    "# ee.Authenticate()\n",
    "ee.Initialize()\n",
    "\n",
    "# URL of the CSV file\n",
    "url = 'https://raw.githubusercontent.com/orwell2024/uscrnlib/main/extract_slides/2024stations_days.csv'\n",
    "\n",
    "# Read the CSV file from the URL\n",
    "response = requests.get(url)\n",
    "data = pd.read_csv(StringIO(response.text))\n",
    "\n",
    "# Filter the data to include only stations from Texas (TX)\n",
    "data_tx = data[data['Station'].str.startswith('TX_')].copy()\n",
    "\n",
    "# Initialize lists to store results\n",
    "results = {\n",
    "    \"Built_1975_50km_percent\": [],\n",
    "    \"Built_2020_50km_percent\": [],\n",
    "    \"Percentage_Change_50km\": [],\n",
    "    \"Built_1975_10km_percent\": [],\n",
    "    \"Built_2020_10km_percent\": [],\n",
    "    \"Percentage_Change_10km\": [],\n",
    "    \"Built_1975_2km_percent\": [],\n",
    "    \"Built_2020_2km_percent\": [],\n",
    "    \"Percentage_Change_2km\": []\n",
    "}\n",
    "\n",
    "# Function to process location and calculate built-up surface percentages\n",
    "def process_location(row, sizeKm):\n",
    "    latitude = row['LATITUDE']\n",
    "    longitude = row['LONGITUDE']\n",
    "\n",
    "    # Define a point for the center of the rectangle at the specified coordinates\n",
    "    centerPoint = ee.Geometry.Point([longitude, latitude])\n",
    "\n",
    "    # Create a bounding box around the center point\n",
    "    halfSideLength = (sizeKm / 2) * 1000  # Convert km to meters\n",
    "    cell = centerPoint.buffer(halfSideLength).bounds()\n",
    "\n",
    "    # Load the built-up surface images for 1975 and 2020 from the JRC GHSL dataset\n",
    "    image_1975 = ee.Image('JRC/GHSL/P2023A/GHS_BUILT_S/1975').select('built_surface')\n",
    "    image_2020 = ee.Image('JRC/GHSL/P2023A/GHS_BUILT_S/2020').select('built_surface')\n",
    "\n",
    "    # Clip the built-up images to the cell\n",
    "    built_1975_clipped = image_1975.clip(cell)\n",
    "    built_2020_clipped = image_2020.clip(cell)\n",
    "\n",
    "    # Calculate the average built-up value for the cell in 1975\n",
    "    mean1975 = built_1975_clipped.reduceRegion(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        geometry=cell,\n",
    "        scale=30,\n",
    "        maxPixels=1e9\n",
    "    ).get('built_surface').getInfo()\n",
    "\n",
    "    # Calculate the average built-up value for the cell in 2020\n",
    "    mean2020 = built_2020_clipped.reduceRegion(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        geometry=cell,\n",
    "        scale=30,\n",
    "        maxPixels=1e9\n",
    "    ).get('built_surface').getInfo()\n",
    "\n",
    "    # Normalize to percentage of the area (1% = 10,000 square meters per hectare)\n",
    "    percentage1975 = round((mean1975 / 10000) * 100, 2) if mean1975 is not None else 0\n",
    "    percentage2020 = round((mean2020 / 10000) * 100, 2) if mean2020 is not None else 0\n",
    "\n",
    "    # Calculate the percentage change\n",
    "    if percentage1975 == 0:\n",
    "        percentage_change = 0\n",
    "    else:\n",
    "        percentage_change = round(((percentage2020 - percentage1975) / percentage1975) * 100, 2)\n",
    "\n",
    "    return percentage1975, percentage2020, percentage_change\n",
    "\n",
    "# Process each location for different cell sizes\n",
    "for index, row in data_tx.iterrows():\n",
    "    # Process for 50km cell\n",
    "    result_50km = process_location(row, 50)\n",
    "    results[\"Built_1975_50km_percent\"].append(result_50km[0])\n",
    "    results[\"Built_2020_50km_percent\"].append(result_50km[1])\n",
    "    results[\"Percentage_Change_50km\"].append(result_50km[2])\n",
    "    \n",
    "    # Process for 10km cell\n",
    "    result_10km = process_location(row, 10)\n",
    "    results[\"Built_1975_10km_percent\"].append(result_10km[0])\n",
    "    results[\"Built_2020_10km_percent\"].append(result_10km[1])\n",
    "    results[\"Percentage_Change_10km\"].append(result_10km[2])\n",
    "    \n",
    "    # Process for 2km cell\n",
    "    result_2km = process_location(row, 2)\n",
    "    results[\"Built_1975_2km_percent\"].append(result_2km[0])\n",
    "    results[\"Built_2020_2km_percent\"].append(result_2km[1])\n",
    "    results[\"Percentage_Change_2km\"].append(result_2km[2])\n",
    "\n",
    "# Add the results to the dataframe\n",
    "for key, value in results.items():\n",
    "    data_tx[key] = value\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "output_csv_path = 'updated_stations_data_tx.csv'\n",
    "data_tx.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(\"Processing is complete and results have been written to the CSV file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b638bbbf-168a-4333-954e-9f68bb3cbd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting batch   0    2024-07-02 14:42:39\n",
      "starting batch   100    2024-07-02 14:46:08\n",
      "starting batch   200    2024-07-02 14:48:43\n",
      "starting batch   300    2024-07-02 14:52:49\n",
      "starting batch   400    2024-07-02 14:56:50\n",
      "starting batch   500    2024-07-02 15:00:37\n",
      "starting batch   600    2024-07-02 15:05:24\n",
      "starting batch   700    2024-07-02 15:09:34\n",
      "starting batch   800    2024-07-02 15:13:28\n",
      "starting batch   900    2024-07-02 15:17:18\n",
      "starting batch   1000    2024-07-02 15:21:04\n",
      "starting batch   1100    2024-07-02 15:25:22\n",
      "starting batch   1200    2024-07-02 15:29:20\n",
      "starting batch   1300    2024-07-02 15:33:04\n",
      "starting batch   1400    2024-07-02 15:36:55\n",
      "starting batch   1500    2024-07-02 15:40:29\n",
      "starting batch   1600    2024-07-02 15:44:47\n",
      "starting batch   1700    2024-07-02 15:48:54\n",
      "starting batch   1800    2024-07-02 15:53:36\n",
      "starting batch   1900    2024-07-02 15:58:32\n",
      "starting batch   2000    2024-07-02 16:03:46\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "import re\n",
    "import time, random\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize the Earth Engine module.\n",
    "# ee.Authenticate()\n",
    "ee.Initialize()\n",
    "\n",
    "# URL of the data\n",
    "url = 'https://data.giss.nasa.gov/gistemp/station_data_v4_globe/v4.temperature.inv.txt'\n",
    "\n",
    "# Fetch the data from the URL\n",
    "response = requests.get(url)\n",
    "data_text = response.text\n",
    "\n",
    "# Clean up the data format\n",
    "data_text = data_text.replace(\"Station Name\", \"Station\")\n",
    "data_text = re.sub(r\"[ \\t]+\", \";\", data_text)\n",
    "\n",
    "while ';;' in data_text:\n",
    "    data_text = data_text.replace(\";;\", \";\")\n",
    "\n",
    "data_lines = data_text.split('\\n')\n",
    "data_lines = [line.rstrip(';') for line in data_lines]\n",
    "\n",
    "cleaned_data_text = \"\\n\".join(data_lines)\n",
    "\n",
    "if not cleaned_data_text.startswith(\"ID;Lat;Lon;Elev-m;Station;BI\"):\n",
    "    cleaned_data_text = cleaned_data_text.replace(\"D;Lat;Lon;Elev-m;Station;BI\", \"ID;Lat;Lon;Elev-m;Station;BI\", 1)\n",
    "\n",
    "data_io = StringIO(cleaned_data_text)\n",
    "\n",
    "valid_rows = []\n",
    "\n",
    "for line in data_io:\n",
    "    fields = line.split(';')\n",
    "    if len(fields) == 6:\n",
    "        valid_rows.append(fields)\n",
    "\n",
    "data = pd.DataFrame(valid_rows, columns=[\"ID\", \"Lat\", \"Lon\", \"Elev-m\", \"Station\", \"BI\"])\n",
    "\n",
    "data['Lat'] = pd.to_numeric(data['Lat'], errors='coerce')\n",
    "data['Lon'] = pd.to_numeric(data['Lon'], errors='coerce')\n",
    "data['BI'] = pd.to_numeric(data['BI'], errors='coerce')\n",
    "\n",
    "data = data.dropna(subset=['Lat', 'Lon', 'BI'])\n",
    "\n",
    "# Initialize lists to store results\n",
    "results = {\n",
    "    \"ID\": [],\n",
    "    \"Station\": [],\n",
    "    \"BI\": [],\n",
    "    \"Built_1975_50km_percent\": [],\n",
    "    \"Built_2020_50km_percent\": [],\n",
    "    \"Percentage_Change_50km\": [],\n",
    "    \"Built_1975_10km_percent\": [],\n",
    "    \"Built_2020_10km_percent\": [],\n",
    "    \"Percentage_Change_10km\": [],\n",
    "    \"Built_1975_2km_percent\": [],\n",
    "    \"Built_2020_2km_percent\": [],\n",
    "    \"Percentage_Change_2km\": []\n",
    "}\n",
    "\n",
    "# Function to process location and calculate built-up surface percentages\n",
    "def process_location(row, sizeKm):\n",
    "    latitude = row['Lat']\n",
    "    longitude = row['Lon']\n",
    "\n",
    "    # Define a point for the center of the rectangle at the specified coordinates\n",
    "    centerPoint = ee.Geometry.Point([longitude, latitude])\n",
    "\n",
    "    # Create a bounding box around the center point\n",
    "    halfSideLength = (sizeKm / 2) * 1000  # Convert km to meters\n",
    "    cell = centerPoint.buffer(halfSideLength).bounds()\n",
    "\n",
    "    # Load the built-up surface images for 1975 and 2020 from the JRC GHSL dataset\n",
    "    image_1975 = ee.Image('JRC/GHSL/P2023A/GHS_BUILT_S/1975').select('built_surface')\n",
    "    image_2020 = ee.Image('JRC/GHSL/P2023A/GHS_BUILT_S/2020').select('built_surface')\n",
    "\n",
    "    # Clip the built-up images to the cell\n",
    "    built_1975_clipped = image_1975.clip(cell)\n",
    "    built_2020_clipped = image_2020.clip(cell)\n",
    "\n",
    "    # Calculate the average built-up value for the cell in 1975\n",
    "    mean1975 = built_1975_clipped.reduceRegion(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        geometry=cell,\n",
    "        scale=30,\n",
    "        maxPixels=1e9\n",
    "    ).get('built_surface').getInfo()\n",
    "\n",
    "    # Calculate the average built-up value for the cell in 2020\n",
    "    mean2020 = built_2020_clipped.reduceRegion(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        geometry=cell,\n",
    "        scale=30,\n",
    "        maxPixels=1e9\n",
    "    ).get('built_surface').getInfo()\n",
    "\n",
    "    # Normalize to percentage of the area (1% = 10,000 square meters per hectare)\n",
    "    percentage1975 = round((mean1975 / 10000) * 100, 2) if mean1975 is not None else 0\n",
    "    percentage2020 = round((mean2020 / 10000) * 100, 2) if mean2020 is not None else 0\n",
    "\n",
    "    # Calculate the percentage change\n",
    "    if percentage1975 == 0:\n",
    "        percentage_change = 0\n",
    "    else:\n",
    "        percentage_change = round(((percentage2020 - percentage1975) / percentage1975) * 100, 2)\n",
    "\n",
    "    return percentage1975, percentage2020, percentage_change\n",
    "\n",
    "# Function to process a batch of locations\n",
    "def process_batch(batch_data):\n",
    "    for index, row in batch_data.iterrows():\n",
    "        # Process for 50km cell\n",
    "        result_50km = process_location(row, 50)\n",
    "        results[\"ID\"].append(row[\"ID\"])\n",
    "        results[\"Station\"].append(row[\"Station\"])\n",
    "        results[\"BI\"].append(row[\"BI\"])\n",
    "        results[\"Built_1975_50km_percent\"].append(result_50km[0])\n",
    "        results[\"Built_2020_50km_percent\"].append(result_50km[1])\n",
    "        results[\"Percentage_Change_50km\"].append(result_50km[2])\n",
    "        \n",
    "        # Process for 10km cell\n",
    "        result_10km = process_location(row, 10)\n",
    "        results[\"Built_1975_10km_percent\"].append(result_10km[0])\n",
    "        results[\"Built_2020_10km_percent\"].append(result_10km[1])\n",
    "        results[\"Percentage_Change_10km\"].append(result_10km[2])\n",
    "        \n",
    "        # Process for 2km cell\n",
    "        result_2km = process_location(row, 2)\n",
    "        results[\"Built_1975_2km_percent\"].append(result_2km[0])\n",
    "        results[\"Built_2020_2km_percent\"].append(result_2km[1])\n",
    "        results[\"Percentage_Change_2km\"].append(result_2km[2])\n",
    "\n",
    "    # Create a DataFrame for the batch results\n",
    "    batch_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Save the batch results to a CSV file\n",
    "    batch_df.to_csv('updated_stations_data_tx.csv', mode='a', index=False, header=not pd.io.common.file_exists('updated_stations_data_tx.csv'))\n",
    "\n",
    "    # Clear the results for the next batch\n",
    "    for key in results.keys():\n",
    "        results[key].clear()\n",
    "\n",
    "# Process the data in batches of 1000\n",
    "batch_size = 100\n",
    "for start_index in range(0, len(data), batch_size):\n",
    "    print (\"starting batch  \", start_index, \"  \", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    end_index = min(start_index + batch_size, len(data))\n",
    "    batch_data = data.iloc[start_index:end_index]\n",
    "    process_batch(batch_data)\n",
    "    sleep_time = random.randint(20, 100)\n",
    "    time.sleep(sleep_time)  # Wait for 1 minute before processing the next batch\n",
    "\n",
    "print(\"Processing is complete and results have been written to the CSV file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "428cf84a-f13b-46e7-893c-bf5e409bea49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-02 14:40:04\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Print the current time\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e9a2db-d60a-443b-ad33-d254cd7290da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
